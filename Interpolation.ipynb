{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smruthishree/StyleGAN2/blob/main/Interpolation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A-kx7MKGmOt",
        "outputId": "fae74747-eae0-479a-92a3-b0dafd77cd64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Total 138 (delta 0), reused 0 (delta 0), pack-reused 138\u001b[K\n",
            "Receiving objects: 100% (138/138), 594.91 KiB | 4.72 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzDuIoMcqfBT",
        "outputId": "336936bb-6c09-49ef-a713-0f1d0b83bdb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 89 (delta 0), reused 0 (delta 0), pack-reused 86\u001b[K\n",
            "Unpacking objects: 100% (89/89), done.\n",
            "/content/stylegan\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kerror: \u001b[m\u001b[Ktest_nvcc.cu: No such file or directory\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K-x c++\u001b[m\u001b[K’ after last input file has no effect\n",
            "\u001b[01m\u001b[Kgcc:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[Kno input files\n",
            "compilation terminated.\n",
            "Tensorflow version: 1.15.2\n",
            "GPU 0: Tesla T4 (UUID: GPU-fae9e027-8a59-4770-d6f0-607cc7ba3132)\n",
            "GPU Identified at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "!git clone https://github.com/NVlabs/stylegan.git\n",
        "%cd stylegan\n",
        "!nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0vyoSnKfYeR",
        "outputId": "15f0b679-a81e-46ae-b3a1-2b8f0a4971c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'stylegan2'\n",
            "/content/stylegan\n"
          ]
        }
      ],
      "source": [
        "cd stylegan2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaaQSoDmEss9",
        "outputId": "5bbcfe0c-c478-486e-cf1b-216528fde96b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Total 138 (delta 0), reused 0 (delta 0), pack-reused 138\u001b[K\n",
            "Receiving objects: 100% (138/138), 594.91 KiB | 4.54 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==1.15.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "ktb19K-3-dZd",
        "outputId": "1a0fba27-7fa7-46b2-a91d-215d4c6e4aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu==1.15.0\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 7.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.46.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.14.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.7 (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.21.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (1.0.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.3.7)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=0b213760fc0e90328a66315f72870ea0f1327a9285246d4197487fc8693f64b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: gast, tensorflow-gpu\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 tensorflow-gpu-1.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorflow",
                  "tensorflow_core"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "ycVz1W0qPgrV",
        "outputId": "d099d6b7-45b9-483b-a341-dfee93f51944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"/content/stylegan2/network-snapshot-009636.pkl\"...\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:97: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:109: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:132: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5378eaecac1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading networks from \"%s\"...'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnetwork_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0m_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_networks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mnoise_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynthesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'noise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/stylegan/pretrained_networks.py\u001b[0m in \u001b[0;36mload_networks\u001b[0;34m(path_or_gdrive_path)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_tf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0m_cached_networks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/stylegan/dnnlib/tflib/network.py\u001b[0m in \u001b[0;36m__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# Set basic fields.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"version\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEasyDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"static_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Download the model of choice\n",
        "import argparse\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "from io import BytesIO\n",
        "import IPython.display\n",
        "import numpy as np\n",
        "from math import ceil\n",
        "from PIL import Image, ImageDraw\n",
        "import imageio\n",
        "\n",
        "import pretrained_networks\n",
        "\n",
        "\n",
        "network_pkl = \"/content/stylegan2/network-snapshot-009636.pkl\"\n",
        "\n",
        "\n",
        "print('Loading networks from \"%s\"...' % network_pkl)\n",
        "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxbhe4uLvF_a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Generates a list of images, based on a list of latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_in_w_space(dlatents, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    Gs_kwargs.truncation_psi = truncation_psi\n",
        "    dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "\n",
        "    imgs = []\n",
        "    for row, dlatent in log_progress(enumerate(dlatents), name = \"Generating images\"):\n",
        "        #row_dlatents = (dlatent[np.newaxis] - dlatent_avg) * np.reshape(truncation_psi, [-1, 1, 1]) + dlatent_avg\n",
        "        dl = (dlatent-dlatent_avg)*truncation_psi   + dlatent_avg\n",
        "        row_images = Gs.components.synthesis.run(dlatent,  **Gs_kwargs)\n",
        "        imgs.append(PIL.Image.fromarray(row_images[0], 'RGB'))\n",
        "    return imgs       \n",
        "\n",
        "def generate_images(zs, truncation_psi):\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_kwargs.randomize_noise = True\n",
        "    if not isinstance(truncation_psi, list):\n",
        "        truncation_psi = [truncation_psi] * len(zs)\n",
        "        \n",
        "    imgs = []\n",
        "    for z_idx, z in log_progress(enumerate(zs), size = len(zs), name = \"Generating images\"):\n",
        "        Gs_kwargs.truncation_psi = truncation_psi[z_idx]\n",
        "        noise_rnd = np.random.RandomState(1) # fix noise\n",
        "        tflib.set_vars({var: noise_rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "        images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "        imgs.append(PIL.Image.fromarray(images[0], 'RGB'))\n",
        "    return imgs\n",
        "\n",
        "def generate_zs_from_seeds(seeds):\n",
        "    zs = []\n",
        "    for seed_idx, seed in enumerate(seeds):\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, *Gs.input_shape[1:]) # [minibatch, component]\n",
        "        zs.append(z)\n",
        "    return zs\n",
        "\n",
        "# Generates a list of images, based on a list of seed for latent vectors (Z), and a list (or a single constant) of truncation_psi's.\n",
        "def generate_images_from_seeds(seeds, truncation_psi):\n",
        "    return generate_images(generate_zs_from_seeds(seeds), truncation_psi)\n",
        "\n",
        "def saveImgs(imgs, location):\n",
        "  for idx, img in log_progress(enumerate(imgs), size = len(imgs), name=\"Saving images\"):\n",
        "    file = location+ str(idx) + \".png\"\n",
        "    img.save(file)\n",
        "\n",
        "def imshow(a, format='png', jpeg_fallback=True):\n",
        "  a = np.asarray(a, dtype=np.uint8)\n",
        "  str_file = BytesIO()\n",
        "  PIL.Image.fromarray(a).save(str_file, format)\n",
        "  im_data = str_file.getvalue()\n",
        "  try:\n",
        "    disp = IPython.display.display(IPython.display.Image(im_data))\n",
        "  except IOError:\n",
        "    if jpeg_fallback and format != 'jpeg':\n",
        "      print ('Warning: image was too large to display in format \"{}\"; '\n",
        "             'trying jpeg instead.').format(format)\n",
        "      return imshow(a, format='jpeg')\n",
        "    else:\n",
        "      raise\n",
        "  return disp\n",
        "\n",
        "def showarray(a, fmt='png'):\n",
        "    a = np.uint8(a)\n",
        "    f = StringIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        "\n",
        "        \n",
        "def clamp(x, minimum, maximum):\n",
        "    return max(minimum, min(x, maximum))\n",
        "    \n",
        "def drawLatent(image,latents,x,y,x2,y2, color=(255,0,0,100)):\n",
        "  buffer = PIL.Image.new('RGBA', image.size, (0,0,0,0))\n",
        "   \n",
        "  draw = ImageDraw.Draw(buffer)\n",
        "  cy = (y+y2)/2\n",
        "  draw.rectangle([x,y,x2,y2],fill=(255,255,255,180), outline=(0,0,0,180))\n",
        "  for i in range(len(latents)):\n",
        "    mx = x + (x2-x)*(float(i)/len(latents))\n",
        "    h = (y2-y)*latents[i]*0.1\n",
        "    h = clamp(h,cy-y2,y2-cy)\n",
        "    draw.line((mx,cy,mx,cy+h),fill=color)\n",
        "  return PIL.Image.alpha_composite(image,buffer)\n",
        "             \n",
        "  \n",
        "def createImageGrid(images, scale=0.25, rows=1):\n",
        "   w,h = images[0].size\n",
        "   w = int(w*scale)\n",
        "   h = int(h*scale)\n",
        "   height = rows*h\n",
        "   cols = ceil(len(images) / rows)\n",
        "   width = cols*w\n",
        "   canvas = PIL.Image.new('RGBA', (width,height), 'white')\n",
        "   for i,img in enumerate(images):\n",
        "     img = img.resize((w,h), PIL.Image.ANTIALIAS)\n",
        "     canvas.paste(img, (w*(i % cols), h*(i // cols))) \n",
        "   return canvas\n",
        "\n",
        "def convertZtoW(latent, truncation_psi=0.7, truncation_cutoff=9):\n",
        "  dlatent = Gs.components.mapping.run(latent, None) # [seed, layer, component]\n",
        "  dlatent_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "  for i in range(truncation_cutoff):\n",
        "    dlatent[0][i] = (dlatent[0][i]-dlatent_avg)*truncation_psi + dlatent_avg\n",
        "    \n",
        "  return dlatent\n",
        "\n",
        "def interpolate(zs, steps):\n",
        "   out = []\n",
        "   for i in range(len(zs)-1):\n",
        "    for index in range(steps):\n",
        "     fraction = index/float(steps) \n",
        "     #out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n",
        "     out.append(zs[i+1]*fraction + zs[i]*(1-fraction))\n",
        "   return out\n",
        "\n",
        "\n",
        "\n",
        "#interpolate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8VnyjDhiBQY",
        "outputId": "fb9bcfd0-822c-4e0a-ccbc-83a0692a2e6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQIhdSRcXC-Q"
      },
      "outputs": [],
      "source": [
        "# generate some random seeds\n",
        "seeds = np.random.randint(10000000, size=2)\n",
        "print(seeds)\n",
        "\n",
        "# show the seeds\n",
        "imshow(createImageGrid(generate_images_from_seeds(seeds, 0.7),0.4,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aZvophLZQOw"
      },
      "outputs": [],
      "source": [
        "# Simple (Z) interpolation\n",
        "zs = generate_zs_from_seeds([2750228,1])\n",
        "\n",
        "latent1 = zs[0]\n",
        "latent2 = zs[1]\n",
        "\n",
        "number_of_steps = 10\n",
        "\n",
        "imgs = generate_images(interpolate([latent1,latent2],number_of_steps), 0.7)\n",
        "number_of_images = len(imgs)\n",
        "imshow(createImageGrid(imgs, 0.5, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwXUbkVJXckp"
      },
      "outputs": [],
      "source": [
        "# generating a MP4 movie\n",
        "\n",
        "zs = generate_zs_from_seeds([421645,6149575,3487643,3766864 ,3857159,5360657,3720613])\n",
        "\n",
        "number_of_steps = 20\n",
        "imgs = generate_images(interpolate(zs,number_of_steps), 1.0)\n",
        "\n",
        "# Example of reading a generated set of images, and storing as MP4.\n",
        "%mkdir out\n",
        "movieName = 'out/mov.mp4'\n",
        "\n",
        "with imageio.get_writer(movieName, mode='I') as writer:\n",
        "    for image in log_progress(list(imgs), name = \"Creating animation\"):\n",
        "        writer.append_data(np.array(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Po7eQSxav8qj"
      },
      "outputs": [],
      "source": [
        "# In order to download files, you can use the snippet below - this often fails for me, though, so I prefer the 'Files' browser in the sidepanel.\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"out/mov.mp4\") \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6DvKKWO254G"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F252sUipCOgO"
      },
      "outputs": [],
      "source": [
        "# If you want to store files to your Google drive, run this cell...\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import os\n",
        "import time\n",
        "print( os.getcwd() )\n",
        "location = \"/content/gdrive/My Drive/results\"\n",
        "print( os.listdir(location) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GofpNwi5aLl9"
      },
      "outputs": [],
      "source": [
        "# more complex example, interpolating in W instead of Z space.\n",
        "zs = generate_zs_from_seeds([421645,6149575,3487643,3766864 ,3857159,5360657,3720613 ])\n",
        "\n",
        "# It seems my truncation_psi is slightly less efficient in W space - I probably introduced an error somewhere...\n",
        "\n",
        "dls = []\n",
        "for z in zs:\n",
        "  dls.append(convertZtoW(z ,truncation_psi=1.0))\n",
        "\n",
        "number_of_steps = 100\n",
        "\n",
        "imgs = generate_images_in_w_space(interpolate(dls,number_of_steps), 1.0)\n",
        "\n",
        "%mkdir out\n",
        "movieName = 'out/mov.mp4'\n",
        "\n",
        "with imageio.get_writer(movieName, mode='I') as writer:\n",
        "    for image in log_progress(list(imgs), name = \"Creating animation\"):\n",
        "        writer.append_data(np.array(image))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Interpolation",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}